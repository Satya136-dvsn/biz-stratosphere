// ================================================================
// DAX Measures for AI-Powered Business Intelligence Platform
// Power BI Dashboards
// ================================================================
// 
// INSTRUCTIONS:
// 1. Open Power BI Desktop
// 2. Go to "Modeling" tab → "New Measure"
// 3. Copy and paste each measure below
// 4. Organize measures into Display Folders (right-click → "Hide in report view" for intermediate calculations)
// ================================================================

// ================================================================
// DASHBOARD 1: REVENUE & KPI MEASURES
// Display Folder: "Revenue Metrics"
// ================================================================

// Basic Revenue Calculation
Total Revenue = 
SUM(data_points[metric_value])

// Month-to-Date Revenue
Revenue MTD = 
TOTALMTD([Total Revenue], data_points[date_recorded])

// Year-to-Date Revenue
Revenue YTD = 
TOTALYTD([Total Revenue], data_points[date_recorded])

// Quarter-to-Date Revenue
Revenue QTD = 
TOTALQTD([Total Revenue], data_points[date_recorded])

// Previous Month Revenue
Revenue Previous Month = 
CALCULATE(
    [Total Revenue],
    DATEADD(data_points[date_recorded], -1, MONTH)
)

// Previous Year Revenue (Same Period)
Revenue Previous Year = 
CALCULATE(
    [Total Revenue],
    SAMEPERIODLASTYEAR(data_points[date_recorded])
)

// Month-over-Month Growth
Revenue MoM Growth = 
[Total Revenue] - [Revenue Previous Month]

// Month-over-Month Growth Percentage
Revenue MoM Growth % = 
DIVIDE(
    [Revenue MoM Growth],
    [Revenue Previous Month],
    0
)

// Year-over-Year Growth
Revenue YoY Growth = 
[Total Revenue] - [Revenue Previous Year]

// Year-over-Year Growth Percentage
Revenue YoY Growth % = 
DIVIDE(
    [Revenue YoY Growth],
    [Revenue Previous Year],
    0
)

// Average Daily Revenue
Avg Daily Revenue = 
AVERAGEX(
    VALUES(data_points[date_recorded]),
    [Total Revenue]
)

// Revenue per Dataset
Revenue per Dataset = 
DIVIDE(
    [Total Revenue],
    DISTINCTCOUNT(data_points[dataset_id]),
    0
)

// Revenue Forecast (30-day moving average)
Revenue Forecast = 
CALCULATE(
    AVERAGE(data_points[metric_value]),
    DATESINPERIOD(
        data_points[date_recorded],
        LASTDATE(data_points[date_recorded]),
        -30,
        DAY
    )
)

// Revenue Target (example: 10% growth over previous year)
Revenue Target = 
[Revenue Previous Year] * 1.10

// Revenue vs Target Variance
Revenue Variance = 
[Total Revenue] - [Revenue Target]

// Revenue vs Target Variance %
Revenue Variance % = 
DIVIDE(
    [Revenue Variance],
    [Revenue Target],
    0
)

// Running Total Revenue
Revenue Running Total = 
CALCULATE(
    [Total Revenue],
    FILTER(
        ALLSELECTED(data_points[date_recorded]),
        data_points[date_recorded] <= MAX(data_points[date_recorded])
    )
)

// ================================================================
// DASHBOARD 1: DATASET METRICS
// Display Folder: "Dataset Metrics"
// ================================================================

// Total Datasets
Total Datasets = 
DISTINCTCOUNT(data_points[dataset_id])

// Active Datasets (with data in last 30 days)
Active Datasets = 
CALCULATE(
    DISTINCTCOUNT(data_points[dataset_id]),
    data_points[date_recorded] >= TODAY() - 30
)

// Dataset Count Growth
Dataset Count Growth = 
[Total Datasets] - 
CALCULATE(
    DISTINCTCOUNT(data_points[dataset_id]),
    DATEADD(data_points[date_recorded], -1, MONTH)
)

// Average Data Points per Dataset
Avg Data Points per Dataset = 
DIVIDE(
    COUNTROWS(data_points),
    [Total Datasets],
    0
)

// ================================================================
// DASHBOARD 2: CHURN PREDICTION MEASURES
// Display Folder: "Churn Metrics"
// ================================================================

// Total Customers
Total Customers = 
DISTINCTCOUNT(churn_predictions_view[customer_id])

// High Risk Customers (Probability > 0.7)
High Risk Customers = 
CALCULATE(
    [Total Customers],
    churn_predictions_view[churn_probability] > 0.7
)

// Medium Risk Customers (0.4 - 0.7)
Medium Risk Customers = 
CALCULATE(
    [Total Customers],
    churn_predictions_view[churn_probability] > 0.4,
    churn_predictions_view[churn_probability] <= 0.7
)

// Low Risk Customers (< 0.4)
Low Risk Customers = 
CALCULATE(
    [Total Customers],
    churn_predictions_view[churn_probability] <= 0.4
)

// High Risk %
High Risk % = 
DIVIDE([High Risk Customers], [Total Customers], 0)

// Medium Risk %
Medium Risk % = 
DIVIDE([Medium Risk Customers], [Total Customers], 0)

// Low Risk %
Low Risk % = 
DIVIDE([Low Risk Customers], [Total Customers], 0)

// Average Churn Probability
Avg Churn Probability = 
AVERAGE(churn_predictions_view[churn_probability])

// Weighted Avg Churn Probability (by monthly charges)
Weighted Avg Churn Probability = 
SUMX(
    churn_predictions_view,
    churn_predictions_view[churn_probability] * churn_predictions_view[monthly_charges]
) / SUM(churn_predictions_view[monthly_charges])

// Total Monthly Revenue
Total Monthly Revenue = 
SUM(churn_predictions_view[monthly_charges])

// Total Annual Revenue
Total Annual Revenue = 
[Total Monthly Revenue] * 12

// Revenue at Risk (High Risk Customers)
Revenue at Risk = 
SUMX(
    FILTER(
        churn_predictions_view,
        churn_predictions_view[churn_probability] > 0.7
    ),
    churn_predictions_view[monthly_charges] * 12
)

// Revenue at Risk %
Revenue at Risk % = 
DIVIDE([Revenue at Risk], [Total Annual Revenue], 0)

// Average Customer Lifetime Value
Avg Customer LTV = 
AVERAGEX(
    churn_predictions_view,
    churn_predictions_view[monthly_charges] * churn_predictions_view[tenure]
)

// Predicted Churn Count
Predicted Churn Count = 
COUNTROWS(
    FILTER(
        churn_predictions_view,
        churn_predictions_view[predicted_churn] = "Yes"
    )
)

// Actual Churn Count
Actual Churn Count = 
COUNTROWS(
    FILTER(
        churn_predictions_view,
        churn_predictions_view[actual_churn] = "Yes"
    )
)

// Churn Rate (Actual)
Churn Rate = 
DIVIDE([Actual Churn Count], [Total Customers], 0)

// Predicted Churn Rate
Predicted Churn Rate = 
DIVIDE([Predicted Churn Count], [Total Customers], 0)

// Average Tenure
Avg Tenure = 
AVERAGE(churn_predictions_view[tenure])

// Average Monthly Charges
Avg Monthly Charges = 
AVERAGE(churn_predictions_view[monthly_charges])

// Customers by Contract Type
Customers Month-to-Month = 
CALCULATE([Total Customers], churn_predictions_view[contract_type] = "Month-to-month")

Customers One Year = 
CALCULATE([Total Customers], churn_predictions_view[contract_type] = "One year")

Customers Two Year = 
CALCULATE([Total Customers], churn_predictions_view[contract_type] = "Two year")

// ================================================================
// DASHBOARD 3: ML MODEL PERFORMANCE MEASURES
// Display Folder: "Model Metrics"
// ================================================================

// Total Predictions
Total Predictions = 
COUNTROWS(predictions_log)

// Predictions with Actuals (for accuracy calculation)
Predictions with Actuals = 
COUNTROWS(
    FILTER(
        predictions_log,
        NOT(ISBLANK(predictions_log[actual_outcome]))
    )
)

// True Positives
True Positives = 
COUNTROWS(
    FILTER(
        predictions_log,
        predictions_log[predicted_label] = TRUE() &&
        predictions_log[actual_outcome] = TRUE()
    )
)

// True Negatives
True Negatives = 
COUNTROWS(
    FILTER(
        predictions_log,
        predictions_log[predicted_label] = FALSE() &&
        predictions_log[actual_outcome] = FALSE()
    )
)

// False Positives
False Positives = 
COUNTROWS(
    FILTER(
        predictions_log,
        predictions_log[predicted_label] = TRUE() &&
        predictions_log[actual_outcome] = FALSE()
    )
)

// False Negatives
False Negatives = 
COUNTROWS(
    FILTER(
        predictions_log,
        predictions_log[predicted_label] = FALSE() &&
        predictions_log[actual_outcome] = TRUE()
    )
)

// Model Accuracy
Model Accuracy = 
DIVIDE(
    [True Positives] + [True Negatives],
    [Predictions with Actuals],
    0
)

// Model Precision
Model Precision = 
DIVIDE(
    [True Positives],
    [True Positives] + [False Positives],
    0
)

// Model Recall (Sensitivity)
Model Recall = 
DIVIDE(
    [True Positives],
    [True Positives] + [False Negatives],
    0
)

// Model Specificity
Model Specificity = 
DIVIDE(
    [True Negatives],
    [True Negatives] + [False Positives],
    0
)

// F1 Score
F1 Score = 
DIVIDE(
    2 * [Model Precision] * [Model Recall],
    [Model Precision] + [Model Recall],
    0
)

// Average Confidence Score
Avg Confidence = 
AVERAGE(predictions_log[confidence_score])

// Average Predicted Probability
Avg Predicted Probability = 
AVERAGE(predictions_log[predicted_probability])

// Predictions This Month
Predictions This Month = 
CALCULATE(
    [Total Predictions],
    DATESMTD(predictions_log[prediction_time])
)

// Predictions Previous Month
Predictions Previous Month = 
CALCULATE(
    [Total Predictions],
    DATEADD(predictions_log[prediction_time], -1, MONTH)
)

// Prediction Growth MoM
Prediction Growth MoM = 
[Predictions This Month] - [Predictions Previous Month]

// Prediction Growth MoM %
Prediction Growth MoM % = 
DIVIDE(
    [Prediction Growth MoM],
    [Predictions Previous Month],
    0
)

// Model Accuracy Target
Model Accuracy Target = 0.85

// Accuracy vs Target
Accuracy vs Target = 
[Model Accuracy] - [Model Accuracy Target]

// Accuracy Status
Accuracy Status = 
IF(
    [Model Accuracy] >= [Model Accuracy Target],
    "✓ Meeting Target",
    "✗ Below Target"
)

// ================================================================
// DASHBOARD 3: API USAGE MEASURES
// Display Folder: "API Metrics"
// ================================================================

// Total API Calls
Total API Calls = 
COUNTROWS(api_usage)

// Average Response Time (ms)
Avg Response Time = 
AVERAGE(api_usage[response_time_ms])

// Success Rate
API Success Rate = 
DIVIDE(
    COUNTROWS(FILTER(api_usage, api_usage[status_code] = 200)),
    [Total API Calls],
    0
)

// Error Rate
API Error Rate = 
DIVIDE(
    COUNTROWS(FILTER(api_usage, api_usage[status_code] >= 400)),
    [Total API Calls],
    0
)

// API Calls This Month
API Calls This Month = 
CALCULATE(
    [Total API Calls],
    DATESMTD(api_usage[created_at])
)

// API Calls per Day
Avg API Calls per Day = 
AVERAGEX(
    VALUES(api_usage[created_at]),
    [Total API Calls]
)

// Peak API Hour
Peak API Hour = 
MAXX(
    SUMMARIZE(
        api_usage,
        HOUR(api_usage[created_at]),
        "Calls", [Total API Calls]
    ),
    [Calls]
)

// ================================================================
// UTILITY MEASURES
// Display Folder: "Calculations" (hide in report view)
// ================================================================

// Selected Date Range (for card display)
Selected Date Range = 
VAR MinDate = MIN(data_points[date_recorded])
VAR MaxDate = MAX(data_points[date_recorded])
RETURN
    FORMAT(MinDate, "MMM DD, YYYY") & " - " & FORMAT(MaxDate, "MMM DD, YYYY")

// Days in Period
Days in Period = 
DATEDIFF(
    MIN(data_points[date_recorded]),
    MAX(data_points[date_recorded]),
    DAY
) + 1

// Months in Period
Months in Period = 
DATEDIFF(
    MIN(data_points[date_recorded]),
    MAX(data_points[date_recorded]),
    MONTH
) + 1

// Is Current Month
Is Current Month = 
MONTH(data_points[date_recorded]) = MONTH(TODAY()) &&
YEAR(data_points[date_recorded]) = YEAR(TODAY())

// Is Current Year
Is Current Year = 
YEAR(data_points[date_recorded]) = YEAR(TODAY())

// ================================================================
// FORMATTING NOTES
// ================================================================
// 
// Apply these formats to measures:
// - Revenue measures: Currency ($) with 2 decimals
// - Percentage measures: Percentage (%) with 1-2 decimals
// - Count measures: Whole number with thousands separator
// - Probability measures: Percentage (%) with 1 decimal
// - Time measures: Whole number with "ms" suffix
// - Accuracy/Precision/Recall: Percentage (%) with 2 decimals
// 
// Add conditional formatting:
// - Growth %: Green if positive, Red if negative
// - Risk levels: Red > 0.7, Yellow 0.4-0.7, Green < 0.4
// - Accuracy: Green if >= 85%, Yellow 75-85%, Red < 75%
// - Response time: Green < 500ms, Yellow 500-1000ms, Red > 1000ms
// 
// ================================================================
