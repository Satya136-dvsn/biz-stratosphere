version: '3.8'

services:
  backend:
    image: ${BACKEND_IMAGE:-ghcr.io/your-org/churn-prediction/backend:latest}
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - backend-logs:/app/logs
    environment:
      - PYTHONUNBUFFERED=1
      - MODEL_DIR=/app/models
      - LOG_LEVEL=INFO
      - SENTRY_DSN=${SENTRY_DSN}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - app-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
      
  frontend:
    image: ${FRONTEND_IMAGE:-ghcr.io/your-org/churn-prediction/frontend:latest}
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - backend
    environment:
      - NODE_ENV=production
    networks:
      - app-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
      
  postgres-airflow:
    image: postgres:14
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${AIRFLOW_DB_USER:-airflow}
      - POSTGRES_PASSWORD=${AIRFLOW_DB_PASSWORD}
      - POSTGRES_DB=${AIRFLOW_DB_NAME:-airflow}
    ports:
      - "5433:5432"
    volumes:
      - airflow-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network
      
  airflow-webserver:
    image: apache/airflow:2.8.0-python3.11
    restart: unless-stopped
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_DB_USER:-airflow}:${AIRFLOW_DB_PASSWORD}@postgres-airflow:5432/${AIRFLOW_DB_NAME:-airflow}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_WEBSERVER_SECRET_KEY}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
    ports:
      - "8080:8080"
    volumes:
      - ./etl:/opt/airflow/dags/etl
      - ./ml:/opt/airflow/dags/ml
      - airflow-logs:/opt/airflow/logs
    command: >
      bash -c "airflow db upgrade &&
               airflow users create --username ${AIRFLOW_ADMIN_USER:-admin} --firstname Admin --lastname User --role Admin --email admin@example.com --password ${AIRFLOW_ADMIN_PASSWORD} || true &&
               airflow webserver"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - app-network
      
  airflow-scheduler:
    image: apache/airflow:2.8.0-python3.11
    restart: unless-stopped
    depends_on:
      postgres-airflow:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_DB_USER:-airflow}:${AIRFLOW_DB_PASSWORD}@postgres-airflow:5432/${AIRFLOW_DB_NAME:-airflow}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
    volumes:
      - ./etl:/opt/airflow/dags/etl
      - ./ml:/opt/airflow/dags/ml
      - airflow-logs:/opt/airflow/logs
    command: airflow scheduler
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  airflow-db:
  airflow-logs:
  backend-logs:
