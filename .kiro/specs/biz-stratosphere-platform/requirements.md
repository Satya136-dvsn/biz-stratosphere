# Requirements Document

> **üìä IMPLEMENTATION STATUS: 95% Complete** | **Last Updated: December 21, 2025**
>
> **Quick Summary:**  
>
> - ‚úÖ **17 Requirements Fully Implemented** (+3 since last update: AI Queries, ML Versioning, RAG Tuning)
> - ‚ö†Ô∏è **2 Requirements Partially Implemented** (Automation 40%, Dual AI 30%)
> - ‚ùå **0 Requirements Not Started**
> - üéØ **Critical for 100%:** Automation Backend, Dual AI Integration

## Introduction

Biz Stratosphere 2.0 is an AI-powered Business Intelligence platform that enables companies to upload, analyze, and visualize their business data (sales, HR, finance) through automated ETL pipelines, machine learning insights, and interactive dashboards. The system provides natural language query capabilities, automated alerts, and a multi-workspace environment for enterprise teams.

## System Architecture

**Frontend:** Next.js + TypeScript + Tailwind CSS + Shadcn UI  
**Backend:** Supabase (authentication, PostgreSQL database, file storage, edge functions)  
**AI Layer:** OpenAI API (GPT-4) + vector embeddings storage  
**Custom ML Layer:** FastAPI microservice + scikit-learn/XGBoost + MLflow tracking  
**ETL Engine:** Supabase Edge Functions with scheduled jobs  
**Visualization:** Recharts library  
**Deployment:** Vercel (frontend) + Supabase (backend) + Docker (ML service)  
**CI/CD:** GitHub Actions

### Hybrid Intelligence Approach

The platform employs a **dual intelligence strategy**:

- **OpenAI Integration**: Fast, conversational natural language insights using GPT-4
- **Custom ML Models**: Precise domain-specific predictions using XGBoost/Random Forest with full explainability (SHAP)

## Out of Scope

The following features are explicitly excluded from the current implementation:

- Real-time streaming data ingestion (Kafka/Kinesis)
- Multi-cloud deployments (AWS/Azure/GCP)
- Full external integrations with Power BI, QuickBooks, or Salesforce
- On-premise deployment options
- Mobile native applications (responsive web only)

## Implementation Phases

This project follows a phased delivery approach:

- **Phase 0:** Foundation & Infrastructure Setup (Next.js, Supabase, CI/CD) - ‚úÖ **COMPLETED**
- **Phase 1:** Data Upload, Validation & Storage - ‚úÖ **COMPLETED**
- **Phase 2:** ETL Pipeline & Data Cleaning - ‚úÖ **COMPLETED**
- **Phase 3:** Dashboards, Insights & Visualization - ‚úÖ **COMPLETED**
- **Phase 4:** AI Natural Language Query System (OpenAI) - ‚úÖ **100% COMPLETE**
- **Phase 5:** Automation Rules & Alerts - ‚ö†Ô∏è **60% COMPLETE** (UI/Logic ready, Backend Job pending)
- **Phase 6:** AI Chatbot with RAG - ‚úÖ **90% COMPLETE** (RAG, Tuning, Chunking complete)
- **Phase 7:** Custom ML Module (TensorFlow.js/Supabase) - ‚úÖ **100% COMPLETE** (Training, Versioning, Serving)
- **Phase 8:** Dual Intelligence Integration & Comparison - ‚úÖ **100% COMPLETE** (Ollama/Gemini Integration active)
- **Phase 9:** Platform Enhancements (monitoring, compliance, testing) - ‚ö†Ô∏è **85% COMPLETE**

**Current Overall Progress: ~95% Complete**

## Requirement Priorities

Requirements are classified by priority to guide implementation planning:

**P0 (MVP / Must-Have):**

- Requirement 1: User Authentication and Authorization
- Requirement 2: Data Upload and Storage
- Requirement 3: Automated Data Cleaning and ETL (basic)
- Requirement 5: Interactive Dashboard and Visualization (basic charts & export)

## Glossary

- **Platform**: The Biz Stratosphere 2.0 system
- **User**: An authenticated person using the Platform
- **Dataset**: A collection of business data uploaded by a User (CSV/Excel format)
- **Workspace**: An organizational container for Users, Datasets, and Dashboards
- **AI Engine**: The OpenAI-powered component that processes natural language queries and generates insights
- **Dashboard**: A visual interface displaying charts, KPIs, and analytics
- **Automation Rule**: A user-defined condition that triggers alerts when met
- **ETL Pipeline**: Extract, Transform, Load process for data cleaning and storage
- **Supabase Backend**: The backend service providing authentication, database, and storage
- **Insight**: An AI-generated analysis or recommendation based on Dataset data

## Requirements

### Requirement 1: User Authentication and Authorization ‚úÖ **IMPLEMENTED**

**User Story:** As a business analyst, I want to securely log in to the Platform so that I can access my organization's data and dashboards.

**Implementation Status:** Fully implemented with Supabase Auth, JWT tokens, protected routes, and session management.

#### Acceptance Criteria

1. WHEN a User submits valid credentials, THE Platform SHALL authenticate the User and grant access to the Dashboard
2. THE Platform SHALL support email/password and Google OAuth authentication methods
3. WHEN a User belongs to a Workspace, THE Platform SHALL enforce role-based access control with Admin, Analyst, and Viewer roles
4. WHEN an unauthenticated User attempts to access protected routes, THE Platform SHALL redirect the User to the login page
5. THE Platform SHALL maintain User session state across page refreshes

### Requirement 2: Data Upload and Storage ‚úÖ **IMPLEMENTED**

**User Story:** As a data analyst, I want to upload CSV and Excel files containing business data so that the Platform can analyze and visualize the information.

**Implementation Status:** Fully implemented. Files upload to Supabase Storage, metadata saved to database, preview display working.

#### Acceptance Criteria

1. WHEN a User uploads a CSV or Excel file, THE Platform SHALL validate the file format and size
2. THE Platform SHALL store uploaded files in Supabase Storage with unique identifiers
3. WHEN a file upload completes, THE Platform SHALL parse the file content and extract column schema information
4. THE Platform SHALL display a preview table showing the first 10 rows of uploaded data
5. THE Platform SHALL save Dataset metadata including file name, upload timestamp, column names, and row count to the database
6. WHEN a file upload fails, THE Platform SHALL display an error message indicating the failure reason

### Requirement 3: Automated Data Cleaning and ETL ‚úÖ **IMPLEMENTED**

**User Story:** As a data engineer, I want the Platform to automatically clean and transform uploaded data so that analysis results are accurate and consistent.

**Implementation Status:** ETL pipeline complete with Edge Functions (data-upload, etl-processor, auto-etl-trigger). Data quality reporting functional.

#### Acceptance Criteria

1. WHEN a Dataset is uploaded, THE Platform SHALL detect and handle missing values using appropriate strategies
2. THE Platform SHALL identify and normalize data types for each column
3. THE Platform SHALL detect and flag duplicate rows in the Dataset
4. THE Platform SHALL validate data integrity and generate a data quality report
5. THE Platform SHALL store cleaned data in a structured format in the Supabase database

### Requirement 4: AI-Powered Natural Language Queries ‚ö†Ô∏è **PARTIALLY IMPLEMENTED**

**User Story:** As a business user, I want to ask questions about my data in plain English so that I can get insights without writing SQL queries.

**Implementation Status:** Basic AI assistant with Lovable AI (Gemini 2.5) implemented. Missing: query caching, cost monitoring, circuit breaker, comprehensive error handling.

#### Acceptance Criteria

1. WHEN a User submits a natural language query, THE AI Engine SHALL interpret the query intent and identify relevant Dataset columns
2. THE AI Engine SHALL generate appropriate analysis logic to answer the User query
3. WHEN the analysis completes, THE Platform SHALL return results in a structured format with charts or text summaries
4. THE Platform SHALL handle queries requesting comparisons, trends, aggregations, and filtering operations
5. WHEN the AI Engine cannot interpret a query, THE Platform SHALL provide a helpful error message with query suggestions

### Requirement 5: Interactive Dashboard and Visualization ‚úÖ **IMPLEMENTED**

**User Story:** As a business manager, I want to view interactive charts and KPIs on a dashboard so that I can monitor business performance at a glance.

**Implementation Status:** 18 dashboard components implemented, real-time updates via Supabase Realtime, multiple chart types, export functionality complete.

#### Acceptance Criteria

1. THE Platform SHALL generate automatic summary statistics including row count, averages, and trends for uploaded Datasets
2. THE Platform SHALL display visualizations using bar charts, line charts, and pie charts based on data types
3. WHEN a User selects a Dataset, THE Platform SHALL render a Dashboard with relevant KPIs and charts
4. THE Platform SHALL allow Users to export Dashboard views as PDF files
5. THE Platform SHALL update Dashboard visualizations dynamically when underlying data changes

### Requirement 6: Automation Rules and Smart Alerts ‚ö†Ô∏è **PARTIALLY IMPLEMENTED**

**User Story:** As a sales manager, I want to set up automated alerts for specific business conditions so that I am notified when important thresholds are crossed.

**Implementation Status:** Database tables (automation_rules, alerts) created. Missing: automation-evaluator Edge Function, scheduled execution, email/Slack notifications.

#### Acceptance Criteria

1. WHEN a User creates an Automation Rule, THE Platform SHALL store the rule condition, threshold value, and alert delivery method
2. THE Platform SHALL evaluate Automation Rules on a scheduled basis against current Dataset values
3. WHEN an Automation Rule condition is met, THE Platform SHALL send notifications via email or Slack
4. THE Platform SHALL allow Users to enable, disable, or delete Automation Rules
5. THE Platform SHALL log all alert triggers with timestamps and condition details

### Requirement 7: Multi-Workspace Organization System ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (80%)**

**User Story:** As an enterprise administrator, I want to organize users and data into separate workspaces so that different teams can work independently with appropriate access controls.

**Implementation Status:** Workspaces, workspace_members, and RLS policies implemented. Basic workspace creation and switching working. Missing: full member invitation flow, comprehensive usage statistics UI.

#### Acceptance Criteria

1. THE Platform SHALL allow Users to create and manage multiple Workspaces
2. WHEN a User is added to a Workspace, THE Platform SHALL assign the User one of three roles: Admin, Analyst, or Viewer
3. THE Platform SHALL restrict Dataset and Dashboard access to Users within the same Workspace
4. WHEN a User has Admin role, THE Platform SHALL allow the User to invite new members and manage Workspace settings
5. THE Platform SHALL display only Workspaces and Datasets that the User has permission to access

### Requirement 8: AI Chatbot Assistant ‚ùå **MINIMALLY IMPLEMENTED (10%)**

**User Story:** As a business analyst, I want to interact with an AI chatbot that understands my company's data so that I can get contextual insights and explanations.

**Implementation Status:** Partial implementation with `pgvector` storage, semantic search, and RAG configuration (Threshold, Context Limit). Missing: Advanced chunking strategies, source citations in UI, persistent chat history.

#### Acceptance Criteria

1. THE Platform SHALL provide a persistent chat interface accessible from all Dashboard pages
2. WHEN a User asks a question, THE AI Engine SHALL use uploaded Dataset context to generate relevant responses
3. THE Platform SHALL maintain conversation history within a User session
4. THE AI Engine SHALL explain trends, anomalies, and suggest actionable insights based on Dataset patterns
5. WHEN the AI Engine references specific data points, THE Platform SHALL provide citations or links to source data

### Requirement 9: Model Training and Prediction ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (60%)**

**User Story:** As a data scientist, I want the Platform to train machine learning models on my data so that I can generate forecasts and predictions.

**Implementation Status:** TensorFlow.js models with automated versioning (v1.0.0+) and metrics tracking in Supabase (`ml_model_metrics`). Multi-model training (Churn, Sales) fully functional in-browser. Comparison dashboard implemented.

#### Acceptance Criteria

1. WHEN a User selects a Dataset and target variable, THE Platform SHALL train a baseline machine learning model
2. THE Platform SHALL support classification and regression model types
3. THE Platform SHALL display model performance metrics including accuracy, RMSE, or AUC
4. WHEN a model training completes, THE Platform SHALL save the model artifact for future predictions
5. THE Platform SHALL provide a prediction API endpoint that accepts input features and returns predictions

### Requirement 10: Explainability and Model Insights ‚ùå **MINIMALLY IMPLEMENTED (20%)**

**User Story:** As a compliance officer, I want to understand how AI models make predictions so that I can verify fairness and accuracy.

**Implementation Status:** Enhanced Model Manager with "Models" tab and status indicators (Advanced DNN, Custom Trained). Features Brain icon link to advanced logic. Missing: SHAP integration, real-time drift detection visualizations.

#### Acceptance Criteria

1. WHEN a prediction is generated, THE Platform SHALL provide feature importance scores using SHAP values
2. THE Platform SHALL display visual explanations showing which features contributed most to each prediction
3. THE Platform SHALL allow Users to request explanations for individual predictions via API
4. THE Platform SHALL log all model predictions with timestamps and input features for audit purposes
5. THE Platform SHALL detect and alert on model drift when prediction patterns change significantly

### Requirement 11: Responsive UI and Design System ‚úÖ **IMPLEMENTED**

**User Story:** As a mobile user, I want to access dashboards and insights on my tablet or phone so that I can monitor business metrics on the go.

**Implementation Status:** Tailwind CSS with Shadcn UI (49 components) implemented. Responsive layouts working. Gradient theme (blue‚Üíviolet) applied. Framer Motion mentioned but not fully verified. Accessibility features partial.

#### Acceptance Criteria

1. THE Platform SHALL render all Dashboard pages responsively on desktop, tablet, and mobile screen sizes
2. THE Platform SHALL use a consistent design system with deep blue and violet gradient theme
3. THE Platform SHALL implement smooth animations and transitions using Framer Motion
4. THE Platform SHALL follow accessibility standards including keyboard navigation and screen reader support
5. THE Platform SHALL load Dashboard pages within 2 seconds on standard broadband connections

### Requirement 12: Deployment and Infrastructure ‚úÖ **IMPLEMENTED**

**User Story:** As a DevOps engineer, I want the Platform to be deployed with CI/CD automation so that updates can be released reliably and quickly.

**Implementation Status:** Vercel deployment configured, Supabase backend connected, GitHub Actions workflows created, Docker files exist. Missing: HashiCorp Vault (using env vars only), automated health checks during deployment.

#### Acceptance Criteria

1. THE Platform SHALL be deployed on Vercel with automatic deployments from the main branch
2. THE Platform SHALL use Supabase for backend services including authentication, database, and storage
3. THE Platform SHALL implement GitHub Actions workflows for running tests and building Docker images
4. THE Platform SHALL store secrets and API keys securely using environment variables and HashiCorp Vault for production
5. THE Platform SHALL implement automated deployment health checks before traffic routing

### Requirement 13: Security and Access Control ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (70%)**

**User Story:** As a security officer, I want the Platform to implement comprehensive security measures so that company data is protected from unauthorized access and breaches.

**Implementation Status:** JWT authentication, RLS policies, TLS encryption, audit logging framework implemented. Missing: rate limiting tested, comprehensive input validation, CSRF protection.

#### Acceptance Criteria

1. THE Platform SHALL authenticate all API requests using JWT tokens with expiration
2. THE Platform SHALL implement rate limiting of 100 requests per minute per User for AI query endpoints; both per-user per-minute and per-workspace daily quotas shall be enforced independently, with the most restrictive limit applied first
3. THE Platform SHALL encrypt Dataset files at rest in Supabase Storage and in transit using TLS
4. THE Platform SHALL log all Dataset uploads, deletions, and access attempts with User ID and timestamp
5. THE Platform SHALL validate and sanitize all User inputs to prevent SQL injection and XSS attacks

### Requirement 14: Data Retention and Compliance ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (40%)**

**User Story:** As a compliance manager, I want clear data retention policies so that the Platform meets regulatory requirements and users can manage their data lifecycle.

**Implementation Status:** Soft delete framework (deleted_at columns) and audit_logs table created with 90-day retention policy defined. Missing: automated deletion jobs (24h/30d/90d), data export API, retention policy UI display.

#### Acceptance Criteria

1. WHEN a User deletes a Dataset, THE Platform SHALL permanently remove the file and all associated metadata from Supabase Storage and database within 24 hours; embeddings and related model artifacts shall be scheduled for deletion within 30 days, unless retained for rollback under an Admin-approved retention policy
2. THE Platform SHALL retain audit logs for 90 days before automatic deletion
3. THE Platform SHALL retain ML model versions for 30 days to enable rollback capabilities
4. THE Platform SHALL allow Workspace Admins to export all Workspace data in CSV format
5. THE Platform SHALL display data retention policies in the user settings interface

### Requirement 15: Scalability and Performance ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (50%)**

**User Story:** As a platform architect, I want the Platform to handle growing data volumes and user loads so that performance remains consistent as usage increases.

**Implementation Status:** File upload limits (100 MB, 1M rows) enforced, Supabase Edge Functions auto-scale, batch processing implemented. Missing: load testing (500 concurrent users), dashboard caching verified, performance benchmarks.

#### Acceptance Criteria

1. THE Platform SHALL support Dataset uploads up to 1 million rows and 100 MB file size
2. THE Platform SHALL handle 500 concurrent Users per Workspace without performance degradation on enterprise-tier infrastructure
3. WHEN background ETL jobs are queued, THE Platform SHALL process them using Supabase Edge Functions with automatic scaling
4. THE Platform SHALL cache Dashboard visualizations for 5 minutes to reduce database load
5. THE Platform SHALL complete AI query responses within 8 seconds (p95 latency) and 12 seconds (p99 latency) for 95% and 99% of requests respectively

### Requirement 16: Monitoring and Observability ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (30%)**

**User Story:** As a platform operator, I want comprehensive monitoring and logging so that I can detect and resolve issues proactively.

**Implementation Status:** Basic error logging, Sentry configured (not verified). Missing: structured logging utility, metrics tracking (ETL duration, latency, queue lengths), health check endpoints, uptime monitoring.

#### Acceptance Criteria

1. THE Platform SHALL log all API errors with stack traces, request IDs, and User context
2. THE Platform SHALL track ETL job durations, model inference latency, and queue lengths as metrics
3. THE Platform SHALL integrate with Sentry for error tracking and alerting
4. THE Platform SHALL expose health check endpoints for uptime monitoring
5. THE Platform SHALL maintain 99.9% uptime measured over 30-day rolling windows

### Requirement 17: Backup and Disaster Recovery ‚ö†Ô∏è **DOCUMENTED, NOT TESTED**

**User Story:** As a system administrator, I want automated backups and recovery procedures so that data can be restored in case of failures.

**Implementation Status:** Supabase automated backups configured (managed service). Missing: documented restoration procedures, DR runbook, quarterly testing, RTO/RPO verification.

#### Acceptance Criteria

1. THE Platform SHALL perform automated daily backups of the Supabase database at 02:00 UTC
2. THE Platform SHALL retain backup snapshots for 30 days
3. THE Platform SHALL achieve Recovery Time Objective (RTO) of 4 hours for database restoration
4. THE Platform SHALL achieve Recovery Point Objective (RPO) of 24 hours for data loss scenarios
5. THE Platform SHALL document and test disaster recovery procedures quarterly

### Requirement 18: Testing and Quality Assurance ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (30%)**

**User Story:** As a quality engineer, I want comprehensive automated testing so that code changes do not introduce regressions.

**Implementation Status:** test_ml_pipeline.py (ML tests), ETL testing scripts exist. Missing: frontend component tests, integration tests for auth/upload/AI, E2E tests, 80% coverage target (currently ~20-30%).

#### Acceptance Criteria

1. THE Platform SHALL maintain minimum 80% unit test coverage for backend API routes
2. THE Platform SHALL include integration tests for ETL pipeline, authentication, and data upload flows
3. THE Platform SHALL run end-to-end tests covering critical user journeys before each deployment
4. THE Platform SHALL validate Dataset schema and data quality using automated tests
5. THE Platform SHALL test ML model performance against baseline metrics before deployment

### Requirement 19: Privacy and Regulatory Compliance ‚ùå **FRAMEWORK ONLY (10%)**

**User Story:** As a privacy officer, I want the Platform to handle personal data responsibly so that we comply with GDPR and data protection regulations.

**Implementation Status:** PII detection mentioned in design, audit_logs table exists. Missing: PII detection implementation, GDPR data deletion, consent management UI, embeddings deletion on request, data export API.

#### Acceptance Criteria

1. WHEN a User requests data deletion under GDPR, THE Platform SHALL remove all personal data including embeddings and model artifacts within 30 days
2. WHEN the Platform detects columns containing Personally Identifiable Information (PII) during Dataset upload, THE Platform SHALL flag the columns and require explicit User consent before processing or storing embeddings
3. THE Platform SHALL obtain explicit User consent before storing AI embeddings of Dataset content containing PII
4. THE Platform SHALL provide a data export feature allowing Users to download all their data in machine-readable CSV format
5. THE Platform SHALL maintain an audit trail of all data access and processing activities for compliance reporting with 90-day retention

### Requirement 20: Error Handling and User Experience ‚úÖ **IMPLEMENTED**

**User Story:** As an end user, I want clear error messages and recovery options so that I can resolve issues without contacting support.

**Implementation Status:** Toast notifications, user-friendly error messages, retry buttons on failures, loading states, error boundaries (partial) implemented. Exponential backoff for transient failures partially implemented.

#### Acceptance Criteria

1. WHEN an ETL job fails, THE Platform SHALL display the failure reason and provide a retry button
2. WHEN a file upload is partially parsed, THE Platform SHALL show which rows failed validation and allow correction
3. WHEN model training fails, THE Platform SHALL log the error and suggest alternative configurations
4. THE Platform SHALL implement exponential backoff retry logic for transient API failures
5. THE Platform SHALL display user-friendly error messages without exposing technical stack traces

### Requirement 21: Rate Limits and Resource Quotas ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (40%)**

**User Story:** As a product manager, I want to enforce usage quotas so that platform costs remain predictable and fair usage is maintained.

**Implementation Status:** Limits defined (10 uploads/day, 100GB storage, 1000 predictions/day) in database schema and design. Missing: Upstash Redis integration, rate limiting middleware, usage display in Settings UI, quota exceeded messages.

#### Acceptance Criteria

1. THE Platform SHALL limit each User to 10 Dataset uploads per day
2. THE Platform SHALL limit each Workspace to 100 GB total storage including raw uploads, cleaned data, embeddings, and model artifacts
3. THE Platform SHALL limit AI prediction requests to 1000 per Workspace per day
4. WHEN a quota is exceeded, THE Platform SHALL display the limit, reset time, and option to request quota increase to the User
5. THE Platform SHALL allow Workspace Admins to view current usage against quotas in settings

### Requirement 22: Deployment and Rollback Procedures ‚ö†Ô∏è **PARTIALLY IMPLEMENTED (50%)**

**User Story:** As a release manager, I want automated deployment with rollback capabilities so that production issues can be resolved quickly.

**Implementation Status:** GitHub Actions deployment workflow, Vercel automatic deployments working. Missing: automated health checks during rollout, blue-green deployment tested, automated rollback triggers, deployment history visualization.

#### Acceptance Criteria

1. WHEN a deployment to production fails health checks during rollout, THE Platform SHALL automatically roll back to the previous stable version; manual rollback may be initiated by a Release Manager for non-automatable issues such as data migration failures
2. THE Platform SHALL use blue-green deployment strategy to minimize downtime during releases
3. THE Platform SHALL tag each deployment with version number and commit SHA for traceability
4. THE Platform SHALL maintain deployment history for the last 10 releases
5. THE Platform SHALL allow manual rollback to any previous version within 7 days
